import { TSqlTextDetail } from "aiqna_common_v1";
import groq from "../../config/groq.js";
import openaiClient from "../../config/openai-client.js";
import { TAnalyzedContentMetadata } from "../../types/shared.js";
import { withRetry } from "../../utils/retry/retry-common.js";
import { sleep } from "../../utils/sleep.js";

/**
 * Text Metadata Extractor with fallback support
 */
export class TextMetadataAnalyzerByAI {
  // ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ (ìš°ì„ ìˆœìœ„ ìˆœ)
  private models = [
    { provider: "groq", model: "llama-3.3-70b-versatile" },
    { provider: "groq", model: "llama-3.1-70b-versatile" },
    { provider: "groq", model: "llama-3.1-8b-instant" },
    { provider: "openai", model: "gpt-4o-mini" },
  ];

  /**
   * Textì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
   */
  async analyzeFromText(
    textData: TSqlTextDetail,
  ): Promise<TAnalyzedContentMetadata> {
    let content = "";

    if (textData.content) {
      content = textData.content.substring(0, 8000);
    }

    if (content.length === 0) {
      console.warn(
        `âš ï¸ No content available for ${textData.hash_key}`
      );
      return {
        categories: [],
        keywords: [],
        locations: [],
        names: [],
        confidence_score: 0,
      };
    }

    const prompt = this.buildPrompt(content);
    const systemPrompt = this.getSystemPrompt();

    // ê° ëª¨ë¸ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„
    for (let i = 0; i < this.models.length; i++) {
      const { provider, model } = this.models[i];

      try {
        console.log(
          `ğŸ”„ Trying ${provider}/${model} for ${textData.hash_key.slice(0, 16)}...`
        );

        // ì¬ì‹œë„ ë¡œì§ê³¼ í•¨ê»˜ ì‹¤í–‰
        const result = await withRetry(
          async () => {
            if (provider === "groq") {
              return await this.analyzeWithGroq(systemPrompt, prompt, model);
            } else {
              return await this.analyzeWithOpenAI(
                systemPrompt,
                prompt,
                model
              );
            }
          },
          {
            maxRetries: 2,
            baseDelay: 15000,
            maxDelay: 60000,
            operationName: `Text metadata extraction (${provider}/${model})`,
            shouldRetry: (error) => {
              const errorMsg = (error as Error).message;
              return (
                errorMsg.includes("503") ||
                errorMsg.includes("over capacity") ||
                errorMsg.includes("internal_server_error")
              );
            },
          }
        );

        console.log(
          `âœ… Successfully extracted metadata using ${provider}/${model}`
        );
        return result;
      } catch (error) {
        const errorMsg = (error as Error).message;
        console.warn(
          `âš ï¸ ${provider}/${model} failed for ${textData.hash_key.slice(0, 16)}...: ${errorMsg}`
        );

        // 503ì´ ì•„ë‹Œ ë‹¤ë¥¸ ì—ëŸ¬ë©´ ì¦‰ì‹œ ì¤‘ë‹¨
        if (
          !errorMsg.includes("503") &&
          !errorMsg.includes("over capacity") &&
          !errorMsg.includes("internal_server_error")
        ) {
          console.error(`âŒ Non-retryable error, returning empty metadata`);
          break;
        }

        // ë§ˆì§€ë§‰ ëª¨ë¸ì´ ì•„ë‹ˆë©´ ë‹¤ìŒ ëª¨ë¸ ì‹œë„
        if (i < this.models.length - 1) {
          console.log(`ğŸ”„ Trying next model...`);
          await sleep(2000);
          continue;
        }
      }
    }

    // ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨ ì‹œ ë¹ˆ ë©”íƒ€ë°ì´í„° ë°˜í™˜
    console.error(
      `âŒ All models failed for ${textData.hash_key.slice(0, 16)}..., returning empty metadata`
    );
    return {
      categories: [],
      keywords: [],
      locations: [],
      names: [],
      confidence_score: 0,
    };
  }

  /**
   * Groq APIë¡œ ë¶„ì„
   */
  private async analyzeWithGroq(
    systemPrompt: string,
    userPrompt: string,
    model: string
  ): Promise<TAnalyzedContentMetadata> {
    const completion = await groq.chat.completions.create({
      messages: [
        {
          role: "system",
          content: systemPrompt,
        },
        {
          role: "user",
          content: userPrompt,
        },
      ],
      model,
      temperature: 0.1,
      max_tokens: 2048,
      response_format: { type: "json_object" },
    });

    return this.parseResponse(completion.choices[0].message.content);
  }

  /**
   * OpenAI APIë¡œ ë¶„ì„ (í´ë°±)
   */
  private async analyzeWithOpenAI(
    systemPrompt: string,
    userPrompt: string,
    model: string
  ): Promise<TAnalyzedContentMetadata> {
    const completion = await openaiClient.chat.completions.create({
      messages: [
        {
          role: "system",
          content: systemPrompt,
        },
        {
          role: "user",
          content: userPrompt,
        },
      ],
      model,
      temperature: 0.1,
      max_tokens: 2048,
      response_format: { type: "json_object" },
    });

    return this.parseResponse(completion.choices[0].message.content);
  }

  /**
   * API ì‘ë‹µ íŒŒì‹±
   */
  private parseResponse(
    content: string | null | undefined
  ): TAnalyzedContentMetadata {
    try {
      const result = JSON.parse(content || "{}");
      return {
        categories: result.categories || [],
        keywords: result.keywords || [],
        locations: result.locations || [],
        names: result.names || [],
        confidence_score: result.confidence_score || 0.5,
      };
    } catch (error) {
      console.error("Failed to parse response:", error);
      return {
        categories: [],
        keywords: [],
        locations: [],
        names: [],
        confidence_score: 0,
      };
    }
  }

  /**
   * Get System Prompt
   */
  private getSystemPrompt(): string {
    return `You are an expert at analyzing text content about Korean travel, food, and lifestyle.

Your task is to extract structured metadata from the text content.

Respond ONLY in valid JSON format:
{
  "categories": ["category1", "category2"],
  "keywords": ["keyword1", "keyword2"],
  "locations": ["location1", "location2"],
  "names": ["name1", "name2"],
  "confidence_score": 0.95
}

**Categories** (select ONLY from this list):
- "cafe" (ì¹´í˜, coffee shops)
- "restaurant" (ìŒì‹ì , ë ˆìŠ¤í† ë‘)
- "shopping" (ì‡¼í•‘, shopping malls, stores)
- "palace" (ê¶ê¶, palaces)
- "history" (ì—­ì‚¬, historical sites)
- "museum" (ë°•ë¬¼ê´€, museums)
- "exhibition" (ì „ì‹œ, exhibitions)
- "themepark" (í…Œë§ˆíŒŒí¬, theme parks)
- "activity" (ì•¡í‹°ë¹„í‹°, activities)
- "experience" (ì²´í—˜, experiences)
- "festival" (ì¶•ì œ, festivals)
- "market" (ì‹œì¥, traditional markets)
- "park" (ê³µì›, parks)
- "tour" (íˆ¬ì–´, tours)

**Keywords** (specific items mentioned):
- Food items: "pasta", "coffee", "dessert", "brunch"
- Activities: "hiking", "shopping", "photography"
- Attributes: "romantic", "family-friendly", "instagram-worthy"

**Locations** (specific place names):
- Neighborhoods: "ì‚¼ì²­ë™", "ê°•ë‚¨", "í™ëŒ€"
- Districts: "ì¢…ë¡œêµ¬", "ê°•ë‚¨êµ¬"
- Landmarks: "ë‚¨ì‚°", "í•œê°•"
- Store/venue names: "ìŠ¤íƒ€ë²…ìŠ¤", "í˜„ëŒ€ë°±í™”ì "

**Names** (people, brands, products):
- Brand names
- Product names
- Celebrity/influencer names (if mentioned)

**Rules:**
1. Extract only information explicitly mentioned in the content
2. Use English for categories, original language for locations/names
3. Maximum 5 items per field
4. confidence_score: 0.0-1.0 based on clarity of information
5. If unsure, use empty array []`;
  }

  /**
   * Build Prompt
   */
  private buildPrompt(content: string): string {
    return `Text Content:
${content}

Extract metadata from this text content following the system instructions.
Return valid JSON only.`;
  }
}