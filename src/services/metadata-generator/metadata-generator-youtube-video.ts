import groq from "../../config/groq.js";
import openaiClient from "../../config/openai-client.js";
import { TAnalyzedContentMetadata } from "../../types/shared.js";
import { withRetry } from "../../utils/retry/retry-common.js";
import { sleep } from "../../utils/sleep.js";

/**
 * Metadata Generator for YouTube Video
 */
export class MetadataGeneratorYouTubeVideo {
  // ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ (ìš°ì„ ìˆœìœ„ ìˆœ)
  private models = [
    { provider: "groq", model: "llama-3.3-70b-versatile" },
    { provider: "groq", model: "llama-3.1-70b-versatile" },
    { provider: "groq", model: "llama-3.1-8b-instant" },
    { provider: "openai", model: "gpt-4o-mini" },
  ];

  /**
   * ì „ì²´ YouTube Video íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
   */
  async generateMetadataFromFullTranscript(
    videoId: string,
    videoTitle: string,
    fullTranscriptText: string,
    language: string,
  ): Promise<TAnalyzedContentMetadata> {
    // í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì²˜ìŒ 8000ìë§Œ ì‚¬ìš© (í† í° ì œí•œ)
    const truncatedText =
      fullTranscriptText.length > 8000
        ? fullTranscriptText.substring(0, 8000) + "..."
        : fullTranscriptText;

    const prompt = this.buildPrompt(videoTitle, truncatedText, language);
    const systemPrompt = this.getSystemPrompt();

    // ê° ëª¨ë¸ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„
    for (let i = 0; i < this.models.length; i++) {
      const { provider, model } = this.models[i];

      try {
        console.log(`ğŸ”„ Trying ${provider}/${model} for video ${videoId}`);

        // ì¬ì‹œë„ ë¡œì§ê³¼ í•¨ê»˜ ì‹¤í–‰
        const result = await withRetry(
          async () => {
            if (provider === "groq") {
              return await this.analyzeWithGroq(systemPrompt, prompt, model);
            } else {
              return await this.analyzeWithOpenAI(systemPrompt, prompt, model);
            }
          },
          {
            maxRetries: 2, // ê° ëª¨ë¸ë‹¹ 2íšŒ ì¬ì‹œë„
            baseDelay: 15000, // Groq Retry-After ì¤€ìˆ˜
            maxDelay: 60000,
            operationName: `Metadata extraction (${provider}/${model})`,
            shouldRetry: (error) => {
              // 503 ë˜ëŠ” over capacity ì—ëŸ¬ë§Œ ì¬ì‹œë„
              const errorMsg = (error as Error).message;
              return (
                errorMsg.includes("503") ||
                errorMsg.includes("over capacity") ||
                errorMsg.includes("internal_server_error")
              );
            },
          },
        );

        console.log(
          `âœ… Successfully extracted metadata using ${provider}/${model}`,
        );
        return result;
      } catch (error) {
        const errorMsg = (error as Error).message;
        console.warn(
          `âš ï¸ ${provider}/${model} failed for ${videoId}: ${errorMsg}`,
        );

        // 503ì´ ì•„ë‹Œ ë‹¤ë¥¸ ì—ëŸ¬ë©´ ë‹¤ìŒ ëª¨ë¸ë¡œ ë„˜ì–´ê°€ì§€ ì•Šê³  ì¦‰ì‹œ ì‹¤íŒ¨
        if (
          !errorMsg.includes("503") &&
          !errorMsg.includes("over capacity") &&
          !errorMsg.includes("internal_server_error")
        ) {
          console.error(`âŒ Non-retryable error, returning empty metadata`);
          break;
        }

        // ë§ˆì§€ë§‰ ëª¨ë¸ì´ ì•„ë‹ˆë©´ ë‹¤ìŒ ëª¨ë¸ ì‹œë„
        if (i < this.models.length - 1) {
          console.log(`ğŸ”„ Trying next model...`);
          await sleep(2000); // ëª¨ë¸ ì „í™˜ ì‹œ 2ì´ˆ ëŒ€ê¸°
          continue;
        }
      }
    }

    // ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨ ì‹œ ë¹ˆ ë©”íƒ€ë°ì´í„° ë°˜í™˜
    console.error(
      `âŒ All models failed for ${videoId}, returning empty metadata`,
    );
    return {
      categories: [],
      keywords: [],
      locations: [],
      names: [],
      confidence_score: 0,
    };
  }

  /**
   * Groq APIë¡œ ë¶„ì„
   */
  private async analyzeWithGroq(
    systemPrompt: string,
    userPrompt: string,
    model: string,
  ): Promise<TAnalyzedContentMetadata> {
    const completion = await groq.chat.completions.create({
      messages: [
        {
          role: "system",
          content: systemPrompt,
        },
        {
          role: "user",
          content: userPrompt,
        },
      ],
      model,
      temperature: 0.1,
      max_tokens: 2048,
      response_format: { type: "json_object" },
    });

    return this.parseResponse(completion.choices[0].message.content);
  }

  /**
   * OpenAI APIë¡œ ë¶„ì„ (í´ë°±)
   */
  private async analyzeWithOpenAI(
    systemPrompt: string,
    userPrompt: string,
    model: string,
  ): Promise<TAnalyzedContentMetadata> {
    const completion = await openaiClient.chat.completions.create({
      messages: [
        {
          role: "system",
          content: systemPrompt,
        },
        {
          role: "user",
          content: userPrompt,
        },
      ],
      model,
      temperature: 0.1,
      max_tokens: 2048,
      response_format: { type: "json_object" },
    });

    return this.parseResponse(completion.choices[0].message.content);
  }

  /**
   * API ì‘ë‹µ íŒŒì‹±
   */
  private parseResponse(
    content: string | null | undefined,
  ): TAnalyzedContentMetadata {
    try {
      const result = JSON.parse(content || "{}");
      return {
        categories: result.categories || [],
        keywords: result.keywords || [],
        locations: result.locations || [],
        names: result.names || [],
        confidence_score: result.confidence_score || 0.5,
      };
    } catch (error) {
      console.error("Failed to parse response:", error);
      return {
        categories: [],
        keywords: [],
        locations: [],
        names: [],
        confidence_score: 0,
      };
    }
  }

  /**
   * Get System Prompt
   */
  private getSystemPrompt(): string {
    return `You are an expert at analyzing YouTube video transcripts about Korean travel, food, and lifestyle content.

Your task is to extract structured metadata from the transcript.

Respond ONLY in valid JSON format:
{
  "categories": ["category1", "category2"],
  "keywords": ["keyword1", "keyword2"],
  "locations": ["location1", "location2"],
  "names": ["name1", "name2"],
  "confidence_score": 0.95
}

**Categories** (select ONLY from this list):
- "cafe" (ì¹´í˜, coffee shops)
- "restaurant" (ìŒì‹ì , ë ˆìŠ¤í† ë‘)
- "shopping" (ì‡¼í•‘, shopping malls, stores)
- "palace" (ê¶ê¶, palaces)
- "history" (ì—­ì‚¬, historical sites)
- "museum" (ë°•ë¬¼ê´€, museums)
- "exhibition" (ì „ì‹œ, exhibitions)
- "themepark" (í…Œë§ˆíŒŒí¬, theme parks)
- "activity" (ì•¡í‹°ë¹„í‹°, activities)
- "experience" (ì²´í—˜, experiences)
- "festival" (ì¶•ì œ, festivals)
- "market" (ì‹œì¥, traditional markets)
- "park" (ê³µì›, parks)
- "tour" (íˆ¬ì–´, tours)

**Keywords** (specific items mentioned):
- Food items: "pasta", "coffee", "dessert", "brunch"
- Activities: "hiking", "shopping", "photography"
- Attributes: "romantic", "family-friendly", "instagram-worthy"

**Locations** (specific place names):
- Neighborhoods: "ì‚¼ì²­ë™", "ê°•ë‚¨", "í™ëŒ€"
- Districts: "ì¢…ë¡œêµ¬", "ê°•ë‚¨êµ¬"
- Landmarks: "ë‚¨ì‚°", "í•œê°•"
- Store/venue names: "ìŠ¤íƒ€ë²…ìŠ¤", "í˜„ëŒ€ë°±í™”ì "

**Names** (people, brands, products):
- Brand names
- Product names
- Celebrity/influencer names (if mentioned)

**Rules:**
1. Extract only information explicitly mentioned in the transcript
2. Use English for categories, original language for locations/names
3. Maximum 5 items per field
4. confidence_score: 0.0-1.0 based on clarity of information
5. If unsure, use empty array []`;
  }

  /**
   * Build Prompt
   */
  private buildPrompt(
    videoTitle: string,
    transcriptText: string,
    language: string,
  ): string {
    return `Video Title: ${videoTitle}
Language: ${language}

Transcript:
${transcriptText}

Extract metadata from this video transcript following the system instructions.
Return valid JSON only.`;
  }
}
